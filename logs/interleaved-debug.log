2026-02-18 00:51:57,234	INFO worker.py:2007 -- Started a local Ray instance.
/m-coriander/coriander/wxdeng/conda-envs/piper_ref/lib/python3.10/site-packages/ray/_private/worker.py:2046: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0
  warnings.warn(
[33m(raylet)[0m [2026-02-18 00:52:07,232 E 448973 449002] (raylet) file_system_monitor.cc:116: /home/wxdeng/ray_tmp/ray/session_2026-02-18_00-51-51_631938_448271 is over 95% full, available space: 18.4005 GB; capacity: 818.202 GB. Object creation will fail if spilling is required.
[36m(run_dp_rank pid=449119)[0m Namespace(model='debug', schedule='interleaved-1f1b', dp=1, pp=2, batch_size=16, mbs=4, seq_len=256, warmup=5, iters=5, tracing=False, naive_gradient_sync=False)
[36m(run_dp_rank pid=449119)[0m Schedule:
[36m(run_dp_rank pid=449119)[0m 0:0:f	0:1:f	2:0:f	2:1:f	0:2:f	0:3:f	2:0:b	 -- 	2:1:b	2:2:f	0:0:b	2:3:f	0:1:b	 -- 	2:2:b	2:3:b	0:2:b	0:3:b	0:0:u	
[36m(run_dp_rank pid=449119)[0m  -- 	1:0:f	1:1:f	3:0:f	3:0:b	3:1:f	3:1:b	1:2:f	1:0:b	1:3:f	1:1:b	3:2:f	3:2:b	3:3:f	3:3:b	1:2:b	1:3:b	1:0:u	 -- 	
[36m(run_dp_rank pid=449119)[0m 2026-02-18 00:52:10,761 - piper_coordinator - DEBUG - Running DP rank 1 of 1
[36m(run_dp_rank pid=449119)[0m 2026-02-18 00:52:10,783 - piper_compile - DEBUG - mbs: 4, stages: 4, devices: 2
[36m(run_dp_rank pid=449119)[0m 2026-02-18 00:52:10,845 - piper_actor - DEBUG - DP rank 0 created actor Actor(PiperActor, dce703cf6d5750dbedad5ef301000000) global rank 0
[36m(run_dp_rank pid=449119)[0m 2026-02-18 00:52:10,846 - piper_actor - DEBUG - DP rank 0 created actor Actor(PiperActor, 4ee27eb1983f38b63b05732f01000000) global rank 1
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:13,881 - piper_actor - INFO - Initializing Ray actor 0 global rank 0 GPU 1
[36m(PiperActor pid=449118)[0m 2026-02-18 00:52:16,330 - piper_actor - DEBUG - Actor 1 has GPU 2, joined the global process group
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:16,331 - piper_actor - INFO - Global rank 0 joined its pp group 0 along with ranks [0, 1]
[36m(run_dp_rank pid=449119)[0m 2026-02-18 00:52:16,547 - piper_compile - INFO - DP rank 1 compiling...
[33m(raylet)[0m [2026-02-18 00:52:17,245 E 448973 449002] (raylet) file_system_monitor.cc:116: /home/wxdeng/ray_tmp/ray/session_2026-02-18_00-51-51_631938_448271 is over 95% full, available space: 18.4005 GB; capacity: 818.202 GB. Object creation will fail if spilling is required.
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:19,337 - piper_actor - INFO - Loading stage 0 graph on actor 0
[36m(PiperActor pid=449118)[0m 2026-02-18 00:52:13,858 - piper_actor - INFO - Initializing Ray actor 1 global rank 1 GPU 2
[36m(run_dp_rank pid=449119)[0m 2026-02-18 00:52:20,873 - piper_backend - WARNING - Should not directly call compiled module, running non-distributed execution
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:16,331 - piper_actor - DEBUG - Actor 0 has GPU 1, joined the global process group
[36m(PiperActor pid=449118)[0m 2026-02-18 00:52:16,331 - piper_actor - INFO - Global rank 1 joined its pp group 0 along with ranks [0, 1]
[33m(raylet)[0m [2026-02-18 00:52:27,257 E 448973 449002] (raylet) file_system_monitor.cc:116: /home/wxdeng/ray_tmp/ray/session_2026-02-18_00-51-51_631938_448271 is over 95% full, available space: 18.4005 GB; capacity: 818.202 GB. Object creation will fail if spilling is required.
[36m(PiperActor pid=449118)[0m 2026-02-18 00:52:20,743 - piper_actor - INFO - Loading stage 3 graph on actor 1[32m [repeated 3x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)[0m
[36m(run_dp_rank pid=449119)[0m Running 5 warmup iterations...
[36m(run_dp_rank pid=449119)[0m 2026-02-18 00:52:27,268 - piper_compile - INFO - DP rank 1 done.
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:27,288 - piper_actor - DEBUG - Actor 0 loaded inputs 1
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:27,304 - piper_actor - DEBUG - Calling forward 0 mb 0 on actor 0
[36m(PiperActor pid=449118)[0m 2026-02-18 00:52:27,302 - piper_actor - DEBUG - Actor 1 loaded labels torch.Size([16, 256, 512])
[36m(PiperActor pid=449118)[0m 2026-02-18 00:52:27,305 - piper_actor - DEBUG - Dispatch fwd p2p recv on 1 from 0
[36m(PiperActor pid=449118)[0m [rank1]:[W218 00:52:27.787363989 ProcessGroupNCCL.cpp:4068] Warning: An unbatched P2P op (send/recv) was called on this ProcessGroup with size 2.  In lazy initialization mode, this will result in a new 2-rank NCCL communicator to be created. (function operator())
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:27,561 - piper_actor - DEBUG - Saving output activation torch.Size([16, 256, 512]) for stage 0 mb 0
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:27,561 - piper_actor - DEBUG - Dispatch fwd p2p send on 0 to 1
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:29,824 - piper_actor - DEBUG - Completed fwd p2p send on 0 to 1
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:29,824 - piper_actor - DEBUG - Forward 0 mb 0 on actor 0 returning [torch.Size([256, 8]), torch.Size([16, 256, 512]), torch.Size([256, 256])]
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:29,836 - piper_actor - DEBUG - Saving output activation torch.Size([16, 256, 512]) for stage 0 mb 1
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:29,836 - piper_actor - DEBUG - Dispatch fwd p2p send on 0 to 1
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:29,837 - piper_actor - DEBUG - Completed fwd p2p send on 0 to 1
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:29,837 - piper_actor - DEBUG - Forward 0 mb 1 on actor 0 returning [torch.Size([256, 8]), torch.Size([16, 256, 512]), torch.Size([256, 256])]
[36m(PiperActor pid=449118)[0m 2026-02-18 00:52:29,833 - piper_actor - DEBUG - Completed fwd p2p recv on 1 from 0
[36m(PiperActor pid=449118)[0m 2026-02-18 00:52:29,833 - piper_actor - DEBUG - Saving input activation torch.Size([16, 256, 512]) for stage 1 mb 0
[36m(PiperActor pid=449118)[0m 2026-02-18 00:52:30,068 - piper_actor - DEBUG - Completed fwd p2p recv on 1 from 0
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:30,286 - piper_actor - DEBUG - Completed fwd p2p send on 0 to 1
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:30,286 - piper_actor - DEBUG - Forward 2 mb 0 on actor 0 returning [torch.Size([16, 256, 512])]
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:30,319 - piper_actor - DEBUG - Completed fwd p2p send on 0 to 1
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:30,319 - piper_actor - DEBUG - Forward 2 mb 1 on actor 0 returning [torch.Size([16, 256, 512])]
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:30,353 - piper_actor - DEBUG - Completed fwd p2p send on 0 to 1
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:30,353 - piper_actor - DEBUG - Forward 0 mb 2 on actor 0 returning [torch.Size([256, 8]), torch.Size([16, 256, 512]), torch.Size([256, 256])]
[36m(PiperActor pid=449118)[0m 2026-02-18 00:52:30,327 - piper_actor - DEBUG - Calling backward 3 mb 0 on actor 1
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:30,407 - piper_actor - DEBUG - Dispatch bwd p2p recv on 0 from 1
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:30,408 - piper_actor - DEBUG - Completed bwd p2p recv on 0 from 1
[36m(PiperActor pid=449117)[0m /m-coriander/coriander/wxdeng/conda-envs/piper_ref/lib/python3.10/site-packages/torch/autograd/graph.py:865: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at /pytorch/aten/src/ATen/cuda/CublasHandlePool.cpp:330.)
[36m(PiperActor pid=449117)[0m   return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:30,485 - piper_actor - DEBUG - Dispatch bwd p2p send on 0 to 1
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:30,485 - piper_actor - DEBUG - Completed bwd p2p send on 0 to 1
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:30,486 - piper_actor - DEBUG - Dispatch bwd p2p recv on 0 from 1
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:30,487 - piper_actor - DEBUG - Completed bwd p2p recv on 0 from 1
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:30,491 - piper_actor - DEBUG - Dispatch bwd p2p send on 0 to 1
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:30,491 - piper_actor - DEBUG - Completed bwd p2p send on 0 to 1
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:30,602 - piper_actor - DEBUG - Actor 0 waiting for backward sync events
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:30,602 - piper_actor - DEBUG - Actor 0 waiting for p2p ops
[36m(run_dp_rank pid=449119)[0m Running 5 timed iterations...
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:31,056 - piper_actor - INFO - Actor 0: Tracing disabled
[36m(run_dp_rank pid=449119)[0m rank 0 iter time= 0.06 Â± 0.00 s (5 samples)
[36m(run_dp_rank pid=449119)[0m rank 0 throughput= 272508.59 tokens/sec (5 samples)
[36m(run_dp_rank pid=449119)[0m Ray timeline saved to: out/debug-pp2-dp1-interleaved-1f1b.json
[36m(PiperActor pid=449118)[0m [rank1]:[W218 00:52:33.737410014 ProcessGroupNCCL.cpp:1553] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
[36m(PiperActor pid=449118)[0m 2026-02-18 00:52:31,344 - piper_actor - DEBUG - Calling forward 3 mb 3 on actor 1[32m [repeated 159x across cluster][0m
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:30,555 - piper_actor - DEBUG - Dispatch fwd p2p recv on 0 from 1[32m [repeated 11x across cluster][0m
[36m(PiperActor pid=449118)[0m [rank1]:[W218 00:52:30.550497856 ProcessGroupNCCL.cpp:4068] Warning: An unbatched P2P op (send/recv) was called on this ProcessGroup with size 2.  In lazy initialization mode, this will result in a new 2-rank NCCL communicator to be created. (function operator())[32m [repeated 3x across cluster][0m
[36m(PiperActor pid=449118)[0m 2026-02-18 00:52:31,347 - piper_actor - DEBUG - Saving output activation torch.Size([16, 256, 512]) for stage 3 mb 3[32m [repeated 158x across cluster][0m
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:30,559 - piper_actor - DEBUG - Dispatch fwd p2p send on 0 to 1[32m [repeated 10x across cluster][0m
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:30,559 - piper_actor - DEBUG - Completed fwd p2p send on 0 to 1[32m [repeated 7x across cluster][0m
[36m(PiperActor pid=449118)[0m 2026-02-18 00:52:31,347 - piper_actor - DEBUG - Forward 3 mb 3 on actor 1 returning [torch.Size([16, 256, 512])][32m [repeated 155x across cluster][0m
[36m(PiperActor pid=449117)[0m 2026-02-18 00:52:30,556 - piper_actor - DEBUG - Completed fwd p2p recv on 0 from 1[32m [repeated 10x across cluster][0m
[36m(PiperActor pid=449118)[0m 2026-02-18 00:52:31,344 - piper_actor - DEBUG - Saving input activation torch.Size([16, 256, 512]) for stage 3 mb 3[32m [repeated 119x across cluster][0m
[36m(PiperActor pid=449118)[0m 2026-02-18 00:52:31,355 - piper_actor - DEBUG - Calling backward 1 mb 3 on actor 1[32m [repeated 159x across cluster][0m
[36m(PiperActor pid=449118)[0m 2026-02-18 00:52:30,589 - piper_actor - DEBUG - Dispatch bwd p2p recv on 1 from 0[32m [repeated 10x across cluster][0m
[36m(PiperActor pid=449118)[0m 2026-02-18 00:52:30,589 - piper_actor - DEBUG - Completed bwd p2p recv on 1 from 0[32m [repeated 10x across cluster][0m
[36m(PiperActor pid=449118)[0m 2026-02-18 00:52:30,595 - piper_actor - DEBUG - Dispatch bwd p2p send on 1 to 0[32m [repeated 10x across cluster][0m
[36m(PiperActor pid=449118)[0m 2026-02-18 00:52:30,595 - piper_actor - DEBUG - Completed bwd p2p send on 1 to 0[32m [repeated 10x across cluster][0m
[36m(PiperActor pid=449118)[0m 2026-02-18 00:52:31,355 - piper_actor - DEBUG - Actor 1 waiting for backward sync events[32m [repeated 19x across cluster][0m
[36m(PiperActor pid=449118)[0m 2026-02-18 00:52:31,355 - piper_actor - DEBUG - Actor 1 waiting for p2p ops[32m [repeated 19x across cluster][0m
[36m(PiperActor pid=449118)[0m 2026-02-18 00:52:31,056 - piper_actor - INFO - Actor 1: Tracing disabled
[36m(PiperActor pid=449117)[0m [rank0]:[W218 00:52:33.814857439 ProcessGroupNCCL.cpp:1553] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
